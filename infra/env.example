# ============================================
# LLM Configuration
# ============================================

# Use Ollama (1) or Bedrock (0)
# Recommended: 1 for local development
USE_OLLAMA=1

# Ollama Settings (if USE_OLLAMA=1)
# Make sure Ollama is running: ollama serve
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# AWS Bedrock Settings (if USE_OLLAMA=0)
AWS_REGION=us-east-1
BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20240620-v1:0
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
BEDROCK_MOCK=0  # Set to 1 for testing (uses mock responses)

# ============================================
# Database Configuration
# ============================================

# Database driver: "clickhouse" or "duckdb"
# Recommended: "clickhouse" for better performance
DB_DRIVER=clickhouse

# ClickHouse settings (if DB_DRIVER=clickhouse)
# For Docker Compose: http://clickhouse:8123
# For local dev: http://localhost:8123
CLICKHOUSE_URL=http://clickhouse:8123

# ============================================
# Service Ports
# ============================================

FRONTEND_PORT=3000
BACKEND_PORT=8000
CLICKHOUSE_HTTP_PORT=8123
